{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13: Loading and Preprocessing Data with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from time import strftime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The `tf.data` API is useful for reading in data gradually from your hard drive and preprocessing data, it revolves around `tf.data.Dataset` which represents a sequence of data items.\n",
    "\n",
    "2. Splitting the data across multiple files can help with shuffling the data, `tf.data.Dataset.list_files()` automatically shuffles the file paths and the `.interleave()` method with argument `cycle_length > 1` will read from multiple files simultaneously. It can also improve performance, setting `num_parallel_calls=tf.data.AUTOTUNE` TensorFlow will choose the right number of threads dynamically based on the available CPU.\n",
    "\n",
    "3. During training if your GPU utilization is very low, the input pipeline might be the bottleneck. You should call `.prefetch()` so that the dataset has a set number of batches ready to go in memory, or if the whole dataset can fit in memory, call `.cache()` after loading and preprocessing the data, but before shuffling, repeating, batching, and prefetching. Other approaches:\n",
    "    * read and preprocess the data with multiple threads in parallel,\n",
    "    * make sure your preprocessing code is optimized,\n",
    "    * save the dataset into multiple TFRecord files,\n",
    "    * if necessary perform some of the preprocessing ahead of time so that it does not need to be done on the fly during training (TF Transform can help with this), &\n",
    "    * if necessary, use a machine with more CPU and RAM, and ensure that the GPU bandwidth is large enough.\n",
    "\n",
    "4. You can save any binary data to a TFRecord file, however in practice *protobufs* are used.\n",
    "\n",
    "5. The `Example` protobuf format has the advantage that TensorFlow provides some operations to parse it (the `tf.io.parse`*`example()` functions) without you having to define your own format. It is sufficiently flexible to represent instances in most datasets.\n",
    "\n",
    "6. Compressing TFRecord files is useful if they need to be loaded via a network connection, e.g. from AWS S3. However, you shouldn't do this if you don't need to as decompressing the files could slow down training.\n",
    "\n",
    "7. Data preprocessing can take place in three ways:\n",
    "    1. when writing the data files\n",
    "        * **pros:** this will speed up training, the training data may also take up less space e.g. you apply dimensionality reduction\n",
    "        * **cons:** however you must make sure you apply the same preprocessing steps in production, its also not easy to try out different preprocessing steps, also not good for data augmentation\n",
    "    2. within the `tf.data` pipeline\n",
    "        * **pros:** its much easier to experiment with preprocessing steps & data augmentation, multithreading and prefetching can make it very efficient, you can use preprocessing layers in your `tf.data` pipeline and then reuse these layers when deploying your model to production\n",
    "        * **cons:** it will still slow down training, each instance will be preprocessed once per epoch (unless you can use `.cache`), must remember to apply the same preprocessing steps in production\n",
    "    3. preprocessing layers of your model\n",
    "        * **pros:** this is good for inference, as your model will be able to handle raw data, you will not run the risk of mismatch between your training preprocessing & inference preprocessing\n",
    "        * **cons:** it will slow down training, with each instance being processed multiple times\n",
    "\n",
    "8. Categorical features can be encoded using integers if there is a natural ordering or one-hot encoding. For text, where each token is a category, you have far too many categories to use one-hot so embeddings make much more sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Fashion MNIST data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.a. Writing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping train_set as directory is not empty.\n",
      "Skipping valid_set as directory is not empty.\n",
      "Skipping test_set as directory is not empty.\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "class_labels = (\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    ")\n",
    "\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(\n",
    "    buffer_size=60_000\n",
    ")\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "valid_size = 2048\n",
    "\n",
    "valid_set = train_set.take(valid_size)\n",
    "train_set = train_set.skip(valid_size)\n",
    "\n",
    "\n",
    "def serialize(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    protobuf_example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                \"image\": tf.train.Feature(\n",
    "                    bytes_list=tf.train.BytesList(value=[image_data.numpy()])\n",
    "                ),\n",
    "                \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return protobuf_example.SerializeToString()\n",
    "\n",
    "\n",
    "data_dir = Path(\"datasets/13/fashion_mnist\")\n",
    "num_shards = 5\n",
    "\n",
    "datasets = {\n",
    "    \"train_set\": train_set,\n",
    "    \"valid_set\": valid_set,\n",
    "    \"test_set\": test_set,\n",
    "}\n",
    "\n",
    "file_paths = dict()\n",
    "for dataset_name, dataset in datasets.items():\n",
    "\n",
    "    dataset_dir = data_dir / dataset_name\n",
    "    dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    file_paths[dataset_name] = [\n",
    "        str(dataset_dir / f\"{dataset_name}-{i}-of-{num_shards}.tfrecord\")\n",
    "        for i in range(1, num_shards + 1)\n",
    "    ]\n",
    "\n",
    "    if not any(dataset_dir.iterdir()):\n",
    "        writers = [\n",
    "            tf.io.TFRecordWriter(file_path) for file_path in file_paths[dataset_name]\n",
    "        ]\n",
    "\n",
    "        for i, (image, label) in dataset.enumerate():\n",
    "            writers[i % num_shards].write(serialize(image, label))\n",
    "\n",
    "        for writer in writers:\n",
    "            writer.close()\n",
    "    else:\n",
    "        print(f\"Skipping {dataset_name} as directory is not empty.\")\n",
    "\n",
    "del (\n",
    "    X_test,\n",
    "    y_test,\n",
    "    y_train,\n",
    "    test_set,\n",
    "    train_set,\n",
    "    valid_set,\n",
    "    data_dir,\n",
    "    dataset,\n",
    "    dataset_dir,\n",
    "    dataset_name,\n",
    "    datasets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(serialized_example):\n",
    "\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    protobuf_example = tf.io.parse_single_example(\n",
    "        serialized_example, feature_description\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        tf.io.parse_tensor(protobuf_example[\"image\"], out_type=tf.uint8),\n",
    "        tf.cast(protobuf_example[\"label\"], tf.uint8),\n",
    "    )\n",
    "\n",
    "\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "norm_layer.adapt(X_train)\n",
    "\n",
    "\n",
    "def preprocess(X, y):\n",
    "    return tf.reshape(norm_layer(X), (28, 28, 1)), y\n",
    "\n",
    "\n",
    "def get_dataset(dataset_name, shuffle=False, sample=None):\n",
    "    dataset = (\n",
    "        tf.data.TFRecordDataset(file_paths[dataset_name], num_parallel_reads=num_shards)\n",
    "        .map(parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .cache()\n",
    "    )\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(60_000 - valid_size)\n",
    "\n",
    "    if sample:\n",
    "        dataset = dataset.take(sample)\n",
    "\n",
    "    return dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "train_dataset = get_dataset(\"train_set\", shuffle=True, sample=4096)\n",
    "valid_dataset = get_dataset(\"valid_set\")\n",
    "test_dataset = get_dataset(\"test_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 21:11:25.832909: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2025-02-05 21:11:25.832923: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2025-02-05 21:11:25.832953: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     20/Unknown - 7s 171ms/step - loss: 2.8020 - accuracy: 0.1750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 21:11:32.885238: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2025-02-05 21:11:32.885266: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    119/Unknown - 24s 167ms/step - loss: 1.8925 - accuracy: 0.3474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 21:11:49.689316: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    121/Unknown - 25s 174ms/step - loss: 1.8839 - accuracy: 0.3505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 21:11:50.497727: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2025-02-05 21:11:50.501520: I tensorflow/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: models/TensorBoard/13/run_2025_02_05_21_11_25/plugins/profile/2025_02_05_21_11_50/Edwards-MacBook-Air.local.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 39s 275ms/step - loss: 1.8577 - accuracy: 0.3569 - val_loss: 1.0060 - val_accuracy: 0.6987\n",
      "Epoch 2/100\n",
      "128/128 [==============================] - 32s 254ms/step - loss: 1.1666 - accuracy: 0.5859 - val_loss: 0.6669 - val_accuracy: 0.7613\n",
      "Epoch 3/100\n",
      "128/128 [==============================] - 33s 259ms/step - loss: 0.9402 - accuracy: 0.6707 - val_loss: 0.6027 - val_accuracy: 0.7829\n",
      "Epoch 4/100\n",
      "128/128 [==============================] - 31s 245ms/step - loss: 0.8095 - accuracy: 0.7148 - val_loss: 0.5038 - val_accuracy: 0.8144\n",
      "Epoch 5/100\n",
      "128/128 [==============================] - 32s 248ms/step - loss: 0.7054 - accuracy: 0.7502 - val_loss: 0.4859 - val_accuracy: 0.8356\n",
      "Epoch 6/100\n",
      "128/128 [==============================] - 32s 251ms/step - loss: 0.6923 - accuracy: 0.7656 - val_loss: 0.4559 - val_accuracy: 0.8382\n",
      "Epoch 7/100\n",
      "128/128 [==============================] - 32s 253ms/step - loss: 0.6075 - accuracy: 0.7861 - val_loss: 0.4313 - val_accuracy: 0.8437\n",
      "Epoch 8/100\n",
      "128/128 [==============================] - 32s 251ms/step - loss: 0.5882 - accuracy: 0.8054 - val_loss: 0.4133 - val_accuracy: 0.8539\n",
      "Epoch 9/100\n",
      "128/128 [==============================] - 32s 248ms/step - loss: 0.5589 - accuracy: 0.8157 - val_loss: 0.3904 - val_accuracy: 0.8627\n",
      "Epoch 10/100\n",
      "128/128 [==============================] - 32s 248ms/step - loss: 0.5281 - accuracy: 0.8240 - val_loss: 0.4181 - val_accuracy: 0.8563\n",
      "Epoch 11/100\n",
      "128/128 [==============================] - 32s 249ms/step - loss: 0.5441 - accuracy: 0.8201 - val_loss: 0.4132 - val_accuracy: 0.8598\n",
      "Epoch 12/100\n",
      "128/128 [==============================] - 32s 251ms/step - loss: 0.5129 - accuracy: 0.8308 - val_loss: 0.3778 - val_accuracy: 0.8602\n",
      "Epoch 13/100\n",
      "128/128 [==============================] - 32s 251ms/step - loss: 0.4852 - accuracy: 0.8369 - val_loss: 0.3538 - val_accuracy: 0.8689\n",
      "Epoch 14/100\n",
      "128/128 [==============================] - 32s 249ms/step - loss: 0.4727 - accuracy: 0.8413 - val_loss: 0.3447 - val_accuracy: 0.8753\n",
      "Epoch 15/100\n",
      "128/128 [==============================] - 32s 250ms/step - loss: 0.4550 - accuracy: 0.8506 - val_loss: 0.3460 - val_accuracy: 0.8714\n",
      "Epoch 16/100\n",
      "128/128 [==============================] - 32s 252ms/step - loss: 0.4708 - accuracy: 0.8411 - val_loss: 0.3505 - val_accuracy: 0.8717\n",
      "Epoch 17/100\n",
      "128/128 [==============================] - 32s 254ms/step - loss: 0.4336 - accuracy: 0.8511 - val_loss: 0.3637 - val_accuracy: 0.8628\n",
      "Epoch 18/100\n",
      "128/128 [==============================] - 32s 252ms/step - loss: 0.4350 - accuracy: 0.8491 - val_loss: 0.3226 - val_accuracy: 0.8776\n",
      "Epoch 19/100\n",
      "128/128 [==============================] - 32s 251ms/step - loss: 0.4264 - accuracy: 0.8560 - val_loss: 0.3220 - val_accuracy: 0.8795\n",
      "Epoch 20/100\n",
      "128/128 [==============================] - 32s 253ms/step - loss: 0.4410 - accuracy: 0.8538 - val_loss: 0.3233 - val_accuracy: 0.8824\n",
      "Epoch 21/100\n",
      "128/128 [==============================] - 32s 251ms/step - loss: 0.4320 - accuracy: 0.8494 - val_loss: 0.3255 - val_accuracy: 0.8726\n",
      "Epoch 22/100\n",
      "128/128 [==============================] - 32s 253ms/step - loss: 0.4287 - accuracy: 0.8613 - val_loss: 0.3399 - val_accuracy: 0.8759\n",
      "Epoch 23/100\n",
      "128/128 [==============================] - 32s 250ms/step - loss: 0.4068 - accuracy: 0.8655 - val_loss: 0.3688 - val_accuracy: 0.8608\n",
      "Epoch 24/100\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.8643Restoring model weights from the end of the best epoch: 19.\n",
      "128/128 [==============================] - 32s 254ms/step - loss: 0.4173 - accuracy: 0.8643 - val_loss: 0.3344 - val_accuracy: 0.8737\n",
      "Epoch 24: early stopping\n"
     ]
    }
   ],
   "source": [
    "DefaultConv2D = partial(\n",
    "    tf.keras.layers.Conv2D,\n",
    "    kernel_size=3,\n",
    "    padding=\"same\",\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "        DefaultConv2D(filters=64, kernel_size=7),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        DefaultConv2D(filters=128),\n",
    "        DefaultConv2D(filters=128),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        DefaultConv2D(filters=256),\n",
    "        DefaultConv2D(filters=256),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=128, activation=\"relu\", kernel_initializer=\"he_normal\"\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=64, activation=\"relu\", kernel_initializer=\"he_normal\"\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            patience=5, restore_best_weights=True, verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            f\"models/TensorBoard/13/{strftime('run_%Y_%m_%d_%H_%M_%S')}\",\n",
    "            profile_batch=\"20,120\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Binary classification of the [Large Movie Review Dataset](https://homl.info/imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that parses a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"datasets/13/aclImdb\")\n",
    "\n",
    "\n",
    "def parse(file_path):\n",
    "    content = tf.io.read_file(file_path)\n",
    "\n",
    "    label = tf.strings.regex_replace(file_path, \".*/(pos|neg)/.*\", \"\\\\1\")\n",
    "    label = tf.cast(tf.equal(label, \"pos\"), tf.int32)\n",
    "\n",
    "    return content, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing some basic analysis of the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = (\n",
    "    tf.data.Dataset.list_files(\n",
    "        [str(data_dir / f\"train/{class_}/*\") for class_ in [\"pos\", \"neg\"]]\n",
    "    )\n",
    "    .map(lambda file_path: parse(file_path)[0], num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(32)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense to set `output_sequence_length=512` in the `TextVectorization` preprocessing layer since many reviews are shorter than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       233.776720\n",
       "std        173.715418\n",
       "min         10.000000\n",
       "50%        174.000000\n",
       "90%        458.000000\n",
       "max       2470.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = []\n",
    "\n",
    "for text_batch in train_text:\n",
    "    for text in text_batch:\n",
    "        num_words = len(str(text.numpy()).split())\n",
    "        lengths.append(num_words)\n",
    "\n",
    "pd.Series(lengths).describe(percentiles=[0.5, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining a good vocabulary size (only the most frequent `max_tokens` will be kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121894"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\"\n",
    ")\n",
    "text_vec_layer.adapt(train_text)\n",
    "\n",
    "vocab_size = len(text_vec_layer.get_vocabulary())\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter()\n",
    "\n",
    "for text_batch in train_text:\n",
    "    for text in text_batch:\n",
    "        standardized_text = re.sub(r\"[^\\w\\s]\", \"\", text.numpy().decode(\"utf-8\").lower())\n",
    "        tokens = str(standardized_text).split()\n",
    "        token_counts.update(tokens)\n",
    "\n",
    "token_counts_df = pd.DataFrame(\n",
    "    list(token_counts.items()), columns=[\"token\", \"count\"]\n",
    ").sort_values(by=\"count\", ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least half of the tokens only appear once in the training text and 90% of the tokens appear $\\leq$ 23 times, which makes training an embedding for them difficult, therefore it makes sense to clip the vocab to 10,000 of the most frequent tokens out of the ~120,000 total token size.\n",
    "\n",
    "i.e. setting `max_tokens=10_000` in my `TextVectorization` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    121045.000000\n",
       "mean         48.083919\n",
       "std        1539.305968\n",
       "min           1.000000\n",
       "50%           1.000000\n",
       "90%          23.000000\n",
       "max      334706.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts_df[\"count\"].describe(percentiles=[0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(\n",
    "    output_sequence_length=512,\n",
    "    max_tokens=10_000,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    ")\n",
    "\n",
    "\n",
    "text_vec_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating train, test, & validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_dataset(train=False):\n",
    "    file_paths = [\n",
    "        str(data_dir / f\"{'train' if train else 'test'}/{class_}/*\")\n",
    "        for class_ in [\"pos\", \"neg\"]\n",
    "    ]\n",
    "    return (\n",
    "        tf.data.Dataset.list_files(file_paths, shuffle=True)\n",
    "        .map(parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .map(\n",
    "            lambda text, label: (text_vec_layer(text), label),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        )\n",
    "        .cache()\n",
    "        .shuffle(25_000)\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset = get_movie_dataset(train=True).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = get_movie_dataset()\n",
    "valid_dataset = test_dataset.take(15_000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.skip(15_000).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 512), dtype=int64, numpy=\n",
       " array([[  85,  111,  773, ...,    0,    0,    0],\n",
       "        [  10,  208,   11, ...,    0,    0,    0],\n",
       "        [ 450,  877,    2, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 132,    7,    2, ...,    0,    0,    0],\n",
       "        [  10,  208,   11, ...,    0,    0,    0],\n",
       "        [3726,   84,  112, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 1, 1, 1, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a model with an `Embedding` layer & then makes predictions based on the mean embedding of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 512, 500)          5000000   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 500)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               50100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5090601 (19.42 MB)\n",
      "Trainable params: 5090601 (19.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "def make_text_model():\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Input(shape=(512)),\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim=text_vec_layer.vocabulary_size(),\n",
    "                output_dim=500,\n",
    "                mask_zero=True,\n",
    "            ),\n",
    "            tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=1)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for _ in range(5):\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                100, activation=\"relu\", kernel_initializer=\"he_normal\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = make_text_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached end learning rate, stopping training\n",
      "Learning rate of minimum loss: 0.0015794261715328444\n"
     ]
    }
   ],
   "source": [
    "class ExponentialLearningRate(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, starting_lr, end_lr, n_iter):\n",
    "        self.factor = (end_lr / starting_lr) ** (1 / n_iter)\n",
    "        self.starting_lr = starting_lr\n",
    "        self.end_lr = end_lr\n",
    "        self.learning_rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.model.optimizer.learning_rate = self.starting_lr\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        lr = self.model.optimizer.learning_rate.numpy() * self.factor\n",
    "        if lr > self.end_lr:\n",
    "            print(\n",
    "                \"\\nReached end learning rate, stopping training\",\n",
    "                f\"Learning rate of minimum loss: {self.learning_rates[np.argmin(self.losses)]}\",\n",
    "                sep=\"\\n\",\n",
    "            )\n",
    "            self.model.stop_training = True\n",
    "\n",
    "        self.model.optimizer.learning_rate = lr\n",
    "        self.learning_rates.append(lr)\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "\n",
    "\n",
    "model = make_text_model()\n",
    "exponential__learning_rate_cb = ExponentialLearningRate(1e-4, 1e-1, 2000)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    callbacks=[exponential__learning_rate_cb],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(\n",
    "    exponential__learning_rate_cb.learning_rates,\n",
    "    exponential__learning_rate_cb.losses,\n",
    ")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Learning Rate\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_ylim(0.29, 0.69)\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 21:25:24.741083: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2025-02-05 21:25:24.741100: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2025-02-05 21:25:24.741118: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655/782 [========================>.....] - ETA: 3s - loss: 0.4245 - accuracy: 0.7863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 21:25:41.988748: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2025-02-05 21:25:41.988767: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/782 [==========================>...] - ETA: 2s - loss: 0.4174 - accuracy: 0.7916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 21:25:45.485244: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2025-02-05 21:25:45.510042: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2025-02-05 21:25:45.510435: I tensorflow/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: models/TensorBoard/13/run_2025_02_05_21_25_24/plugins/profile/2025_02_05_21_25_45/Edwards-MacBook-Air.local.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 27s 33ms/step - loss: 0.4055 - accuracy: 0.7996 - val_loss: 0.3555 - val_accuracy: 0.8383\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.2377 - accuracy: 0.9048 - val_loss: 0.2855 - val_accuracy: 0.8846\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.1878 - accuracy: 0.9258 - val_loss: 0.3434 - val_accuracy: 0.8501\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.1492 - accuracy: 0.9426 - val_loss: 0.3915 - val_accuracy: 0.8566\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.1151 - accuracy: 0.9547 - val_loss: 0.5139 - val_accuracy: 0.8556\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.0919 - accuracy: 0.9639 - val_loss: 0.4586 - val_accuracy: 0.8671\n",
      "Epoch 7/100\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9694Restoring model weights from the end of the best epoch: 2.\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.0762 - accuracy: 0.9694 - val_loss: 0.5357 - val_accuracy: 0.8587\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = make_text_model()\n",
    "model.optimizer.learning_rate = 1.5e-3 / 2\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            patience=5, restore_best_weights=True, verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            f\"models/TensorBoard/13/{strftime('run_%Y_%m_%d_%H_%M_%S')}\",\n",
    "            profile_batch=\"650,700\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 23:01:05.009189: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "datasets = tfds.load(name=\"imdb_reviews\")\n",
    "train_set, test_set = datasets[\"train\"], datasets[\"test\"]\n",
    "for example in train_set.take(1):\n",
    "    print(example[\"text\"])\n",
    "    print(example[\"label\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homl3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
